**************************************************************
Task 1
git clone https://github.com/GoogleCloudPlatfor...

Create a storage bucket (Regional, us-central1)
**************************************************************
Task 2
Create CLoud FUnction
name : saf-longrun-job-func
Trigger : Cloud Storage
Event Type : Finalize/Create
Browse and select your bucket 

Save and next 
Replace index.js and package.json from the code in repo'
'https://github.com/GoogleCloudPlatfor...
Entry point : safLongRunJobFunc

**************************************************************
Task 3
Goto Bigquery, select project and click create dataset
name : lab
**************************************************************
Task 4
goto pub/Sub 

Create topic named speech2text
**************************************************************
Tassk 5 
Create a folder DFaudio inside the storage bucket
**************************************************************
Task 6

cd dataflow-contact-center-speech-analysis/saf-longrun-job-dataflow

python -m virtualenv env -p python3
source env/bin/activate
pip install apache-beam[gcp]
pip install dateparser

export PROJECT_ID=[YOUR_PROJECT_ID]
export TOPIC_NAME=speech2text
export BUCKET_NAME=[YOUR_BUCKET_NAME]
export DATASET_NAME=lab
export TABLE_NAME=transcript

enable doalogflow API from console 

python3 saflongrunjobdataflow.py --project=$PROJECT_ID --input_topic=projects/$PROJECT_ID/topics/$TOPIC_NAME --runner=DataflowRunner --region=us-central1 --temp_location=gs://$BUCKET_NAME/tmp --output_bigquery=$DATASET_NAME.$TABLE_NAME --requirements_file="requirements.txt"
**************************************************************

Task 7

gsutil -h x-goog-meta-callid:1234567 -h x-goog-meta-stereo:false -h x-goog-meta-pubsubtopicname:$TOPIC_NAME -h x-goog-meta-year:2019 -h x-goog-meta-month:11 -h x-goog-meta-day:06 -h x-goog-meta-starttime:1116 cp gs://qwiklabs-bucket-gsp311/speech_commercial_mono.flac gs://$BUCKET_NAME

# stereo wav audio sample
gsutil -h x-goog-meta-callid:1234567 -h x-goog-meta-stereo:true -h x-goog-meta-pubsubtopicname:$TOPIC_NAME -h x-goog-meta-year:2019 -h x-goog-meta-month:11 -h x-goog-meta-day:06 -h x-goog-meta-starttime:1116 cp gs://qwiklabs-bucket-gsp311/speech_commercial_stereo.wav gs://$BUCKET_NAME
**************************************************************
Task 8 
goto bigquery, select the table generated by pipeline 
click on 'More' then 'Query Settings'
Specify a name 'copied' and save 

run this query 
SELECT * FROM `[YOUR_PROJECT_ID].[DATASET_NAME].[TABLE]`

goto query results, export, scan with dlp, give a name and clcik create.
**************************************************************
